# DataLakeHouse - Olist E-commerce Analytics

## üìã T·ªïng quan d·ª± √°n

H·ªá th·ªëng Data Lakehouse x·ª≠ l√Ω v√† ph√¢n t√≠ch d·ªØ li·ªáu th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ Olist s·ª≠ d·ª•ng ki·∫øn tr√∫c Medallion (Bronze ‚Üí Silver ‚Üí Gold) v·ªõi Apache Spark, Delta Lake, v√† MinIO.

### üéØ M·ª•c ti√™u

- X√¢y d·ª±ng pipeline ETL t·ª± ƒë·ªông h√≥a v·ªõi Change Data Capture (CDC)
- √Åp d·ª•ng ki·∫øn tr√∫c Medallion ƒë·ªÉ qu·∫£n l√Ω ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu
- Thi·∫øt k·∫ø Star Schema cho ph√¢n t√≠ch d·ªØ li·ªáu
- T√≠ch h·ª£p c√°c c√¥ng c·ª• BI/Analytics hi·ªán ƒë·∫°i

### üèóÔ∏è Ki·∫øn tr√∫c h·ªá th·ªëng

![architecture](./doc/architecture.png)

### üõ†Ô∏è Stack c√¥ng ngh·ªá

| Th√†nh ph·∫ßn | C√¥ng ngh·ªá | Port |
|------------|-----------|------|
| Source DB | PostgreSQL | 5432 |
| CDC | Debezium Connect | 8083 |
| Messaging | Apache Kafka | 9092 |
| Storage | MinIO | 9000/9001 |
| Processing | Apache Spark | 7077/8080 |
| Query Engine | Trino | 8082 |
| Orchestration | Apache Airflow | 8081 |
| BI | Metabase | 3000 |
| Monitoring | Kafka UI | 8084 |

---

## üöÄ H∆∞·ªõng d·∫´n ch·∫°y t·ª´ng b∆∞·ªõc

### B∆∞·ªõc 1: Kh·ªüi ƒë·ªông h·ªá th·ªëng

```bash
# Clone repository
git clone https://github.com/koi132/DataLakeHouse.git
cd DataLakeHouse

# Start all services
docker-compose up --build -d

# Verify services
docker ps
```

### B∆∞·ªõc 2: T·∫°o databases

```bash
# Create Airflow database
docker exec -it postgres psql -U postgres -c "CREATE DATABASE airflow;"

# Create Metabase database
docker exec -it postgres psql -U postgres -c "CREATE DATABASE metabase;"
```

### B∆∞·ªõc 3: Import d·ªØ li·ªáu v√†o PostgreSQL

```bash
# Copy dataset v√†o container
docker cp dataset/ecommerce/. postgres:/tmp/

# Copy SQL scripts
docker cp Script/. postgres:/tmp/

# T·∫°o tables
docker exec -it postgres psql -U postgres -d orders -f /tmp/create_tables.sql

# Import data
docker exec -it postgres psql -U postgres -d orders -f /tmp/import_raw.sql
```

### B∆∞·ªõc 4: ƒêƒÉng k√Ω Debezium CDC Connector

**PowerShell:**

```powershell
curl.exe -X POST http://localhost:8083/connectors `
  -H "Content-Type: application/json" `
  -d "@e:\Projects\DataLakeHouse\connectors\postgres-olist-initial.json"
```

**Bash/CMD:**

```bash
curl -X POST http://localhost:8083/connectors -H "Content-Type: application/json" -d "@connectors/postgres-olist-initial.json"
```

### B∆∞·ªõc 5: Ch·∫°y Spark Streaming (Kafka ‚Üí Bronze)

```bash
# V√†o Spark container
docker exec -it spark-master bash

# Submit streaming job
/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,\
org.apache.kafka:kafka-clients:3.5.1,\
org.apache.hadoop:hadoop-aws:3.3.2,\
com.amazonaws:aws-java-sdk-bundle:1.12.262,\
io.delta:delta-spark_2.12:3.2.0 \
  /opt/spark/app/stream_kafka_to_bronze.py
```

### B∆∞·ªõc 6: Register Bronze tables v√†o Hive Metastore

```bash
/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages io.delta:delta-spark_2.12:3.2.0,org.apache.hadoop:hadoop-aws:3.3.4 \
  /opt/spark/app/register_bronze_hms.py
```

### B∆∞·ªõc 7: Ch·∫°y Bronze ‚Üí Silver ETL

```bash
/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages io.delta:delta-spark_2.12:3.2.0,org.apache.hadoop:hadoop-aws:3.3.4 \
  /opt/spark/app/process_bronze_to_silver.py
```

### B∆∞·ªõc 8: Ch·∫°y Silver ‚Üí Gold ETL

```bash
/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages io.delta:delta-spark_2.12:3.2.0,org.apache.hadoop:hadoop-aws:3.3.4 \
  /opt/spark/app/process_silver_to_gold.py
```

---
### Galaxy Schema

![architecture](./doc/schema.png)

---

## üîç Truy c·∫≠p Services

| Service | URL | Credentials |
|---------|-----|-------------|
| Airflow | http://localhost:8081 | airflow / airflow |
| MinIO Console | http://localhost:9001 | admin / password123 |
| Spark Master UI | http://localhost:8080 | - |
| Kafka UI | http://localhost:8084 | - |
| Trino UI | http://localhost:8082 | - |
| Metabase | http://localhost:3000 | - |

---

## üìä D·ªØ li·ªáu

### Bronze Layer

- Raw CDC data t·ª´ Kafka
- Format: Delta Lake
- Location: `s3a://bronze/`

### Silver Layer

- Cleaned & transformed data
- Deduplication, type casting, business rules
- Location: `s3a://silver/`

### Gold Layer

- Star Schema (Dimensions + Facts)
- Optimized for analytics
- Location: `s3a://gold/`

**Dimension Tables:** dim_geography, dim_date, dim_customer, dim_seller, dim_product, dim_order_status

**Fact Tables:** fact_order_items, fact_reviews

---

